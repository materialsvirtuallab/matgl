from __future__ import annotations

import torch
from matgl.utils.so3 import (
    generate_clebsch_gordan,
    generate_clebsch_gordan_rsh,
    generate_sh_to_rsh,
    round_cmp,
    sh_indices,
    sparsify_clebsch_gordon,
)


def test_sh_indices():
    # Test case 1: lmax = 0
    lmax_0 = 0
    lidx_0, midx_0 = sh_indices(lmax_0)
    assert torch.equal(lidx_0, torch.tensor([0]))  # Expected lidx result
    assert torch.equal(midx_0, torch.tensor([0]))  # Expected midx result

    # Test case 2: lmax = 1
    lmax_1 = 1
    lidx_1, midx_1 = sh_indices(lmax_1)
    assert torch.equal(lidx_1, torch.tensor([0, 1, 1, 1]))  # Expected lidx result
    assert torch.equal(midx_1, torch.tensor([0, -1, 0, 1]))  # Expected midx result

    # Test case 3: lmax = 2
    lmax_2 = 2
    lidx_2, midx_2 = sh_indices(lmax_2)
    assert torch.equal(lidx_2, torch.tensor([0, 1, 1, 1, 2, 2, 2, 2, 2]))  # Expected lidx result
    assert torch.equal(midx_2, torch.tensor([0, -1, 0, 1, -2, -1, 0, 1, 2]))  # Expected midx result


def test_generate_sh_to_rsh():
    # Test case 1: lmax = 0
    lmax_0 = 0
    U_0 = generate_sh_to_rsh(lmax_0)
    assert torch.equal(U_0, torch.eye(1))  # Expected U result

    # Test case 2: lmax = 1
    lmax_1 = 1
    U_1 = generate_sh_to_rsh(lmax_1)
    expected_U_1 = torch.tensor(
        [
            [1.0000 + 0.0000j, 0.0000 + 0.0000j, 0.0000 + 0.0000j, 0.0000 + 0.0000j],
            [0.0000 + 0.0000j, 0.0000 + 0.7071j, 0.0000 + 0.0000j, 0.0000 + 0.7071j],
            [0.0000 + 0.0000j, 0.0000 + 0.0000j, 1.0000 + 0.0000j, 0.0000 + 0.0000j],
            [0.0000 + 0.0000j, 0.7071 + 0.0000j, 0.0000 + 0.0000j, -0.7071 + 0.0000j],
        ]
    )
    assert torch.allclose(U_1, expected_U_1)  # Use torch.allclose for numerical comparisons

    # Test case 3: lmax = 2
    lmax_2 = 2
    U_2 = generate_sh_to_rsh(lmax_2)
    expected_U_2 = torch.tensor(
        [
            [
                1.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
            ],
            [
                0.0000 + 0.0000j,
                0.0000 + 0.7071j,
                0.0000 + 0.0000j,
                0.0000 + 0.7071j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
            ],
            [
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                1.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
            ],
            [
                0.0000 + 0.0000j,
                0.7071 + 0.0000j,
                0.0000 + 0.0000j,
                -0.7071 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                -0.0000 + 0.0000j,
                0.0000 + 0.0000j,
            ],
            [
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.7071j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 - 0.7071j,
            ],
            [
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.7071j,
                0.0000 + 0.0000j,
                0.0000 + 0.7071j,
                0.0000 + 0.0000j,
            ],
            [
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                1.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
            ],
            [
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                -0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.7071 + 0.0000j,
                0.0000 + 0.0000j,
                -0.7071 + 0.0000j,
                0.0000 + 0.0000j,
            ],
            [
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.7071 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.0000 + 0.0000j,
                0.7071 + 0.0000j,
            ],
        ]
    )
    assert torch.allclose(U_2, expected_U_2)  # Use torch.allclose for numerical comparisons


def test_generate_clebsch_gordan():
    # Test case 1: lmax = 0
    lmax_0 = 0
    cg_0 = generate_clebsch_gordan(lmax_0)
    assert torch.equal(cg_0, torch.tensor([[[1.0]]]))  # Expected cg result

    # Test case 2: lmax = 1
    lmax_1 = 1
    cg_1 = generate_clebsch_gordan(lmax_1)
    expected_cg_1 = torch.tensor(
        [
            [
                [1.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 1.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 1.0000],
            ],
            [
                [0.0000, 1.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.7071, 0.0000, 0.0000],
                [0.5774, 0.0000, -0.7071, 0.0000],
            ],
            [
                [0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.7071, 0.0000, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.7071],
            ],
            [
                [0.0000, 0.0000, 0.0000, 1.0000],
                [0.5774, 0.0000, 0.7071, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.7071],
                [0.0000, 0.0000, 0.0000, 0.0000],
            ],
        ]
    )
    assert torch.allclose(cg_1, expected_cg_1, atol=1e-4)  # Use torch.allclose for numerical comparisons

    # Test case 3: lmax = 2
    lmax_2 = 2
    cg_2 = generate_clebsch_gordan(lmax_2)
    print(cg_2)
    # Set expected values based on specific cases
    expected_cg_2 = torch.tensor(
        [
            [
                [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],
            ],
            [
                [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.7071, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000],
                [0.5774, 0.0000, -0.7071, 0.0000, 0.0000, 0.0000, 0.4082, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, -0.5774, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.3162, 0.0000, 0.0000, 0.0000, -0.7071, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.5477, 0.0000, 0.0000, 0.0000, -0.7071, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.7746, 0.0000, 0.0000, 0.0000, -0.5774, 0.0000],
            ],
            [
                [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8165, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.7071, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.8165, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.4082, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.6325, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, -0.4082, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.8165],
            ],
            [
                [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.5774, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.4082, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],
                [0.0000, 0.7746, 0.0000, 0.0000, 0.0000, 0.5774, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.5477, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.3162, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5774],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, -0.8165, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.7746, 0.0000, 0.0000, 0.0000, -0.5774, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.4472, 0.0000, 0.0000, 0.0000, 0.6547, 0.0000, 0.0000, 0.0000],
                [0.4472, 0.0000, -0.6325, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.5774, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.5477, 0.0000, 0.0000, 0.0000, -0.4082, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.5477, 0.0000, 0.0000, 0.0000, -0.7071, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, -0.6547, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.5477, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000, 0.0000, 0.0000],
                [-0.4472, 0.0000, 0.3162, 0.0000, 0.0000, 0.0000, 0.2673, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.4472, 0.0000, 0.0000, 0.0000, 0.6547, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
                [0.0000, 0.3162, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.6325, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.3162, 0.0000, 0.0000, 0.0000, -0.7071, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.5477, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000, 0.0000, 0.0000],
                [0.4472, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.5345, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.5477, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5345],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.0000, 0.5477, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.4082, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.5774],
                [0.0000, 0.4472, 0.0000, 0.0000, 0.0000, 0.6547, 0.0000, 0.0000, 0.0000],
                [-0.4472, 0.0000, -0.3162, 0.0000, 0.0000, 0.0000, 0.2673, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.6547],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],
                [0.0000, 0.0000, 0.0000, 0.7746, 0.0000, 0.0000, 0.0000, 0.5774, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8165],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.4472, 0.0000, 0.6325, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.4472, 0.0000, 0.0000, 0.0000, 0.6547, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5345],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
            ],
        ]
    )

    assert torch.allclose(cg_2, expected_cg_2, atol=1e-4)  # Use torch.allclose for numerical comparisons


def test_generate_clebsch_gordan_rsh():
    # Test case 1: lmax = 0
    lmax_0 = 0
    cg_rsh_0 = generate_clebsch_gordan_rsh(lmax_0)
    expected_cg_rsh_0 = torch.eye(1).unsqueeze(0)  # Expected cg_rsh result
    assert torch.allclose(cg_rsh_0, expected_cg_rsh_0, atol=1e-4)  # Use torch.allclose for numerical comparisons

    # Test case 2: lmax = 1
    lmax_1 = 1
    cg_rsh_1 = generate_clebsch_gordan_rsh(lmax_1)
    expected_cg_rsh_1 = torch.tensor(
        [
            [
                [1.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 1.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 1.0000],
            ],
            [
                [0.0000, 1.0000, 0.0000, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 1.0000],
                [0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000],
            ],
        ]
    )
    assert torch.allclose(cg_rsh_1, expected_cg_rsh_1, atol=1e-4)  # Use torch.allclose for numerical comparisons

    # Test case 3: lmax = 2
    lmax_2 = 2
    cg_rsh_2 = generate_clebsch_gordan_rsh(lmax_2)
    # Define the expected values based on specific cases
    expected_cg_rsh_2 = torch.tensor(
        [
            [
                [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],
            ],
            [
                [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4082, 0.0000, -0.7071],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.3162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8165, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.6325, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000],
                [-0.5774, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4082, 0.0000, 0.7071],
                [0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.3162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.4472, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000],
                [0.4472, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000, 0.4629],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4629, 0.0000, 0.0000, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
                [0.0000, 0.3162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.6325, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.3162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000, 0.0000, 0.0000],
                [0.4472, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.5345, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5345],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000],
                [0.4472, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.2673, 0.0000, -0.4629],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000],
            ],
            [
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],
                [0.0000, 0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, -0.5477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4629, 0.0000, 0.0000, 0.0000],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5345],
                [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4629, 0.0000],
                [0.4472, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5345, 0.0000, 0.0000],
            ],
        ]
    )
    assert torch.allclose(cg_rsh_2, expected_cg_rsh_2, atol=1e-4)  # Use torch.allclose for numerical comparisons


def test_sparsify_clebsch_gordon():
    # Test case 1: lmax = 0
    lmax_0 = 0
    cg_0 = generate_clebsch_gordan(lmax_0)
    cg_sparse_0, idx_in_1_0, idx_in_2_0, idx_out_0 = sparsify_clebsch_gordon(cg_0)
    assert torch.allclose(cg_sparse_0, torch.tensor([1.0]), atol=1e-6)  # Use torch.allclose for numerical comparisons
    assert torch.allclose(idx_in_1_0, torch.tensor([0]), atol=1e-6)
    assert torch.allclose(idx_in_2_0, torch.tensor([0]), atol=1e-6)
    assert torch.allclose(idx_out_0, torch.tensor([0]), atol=1e-6)

    # Test case 2: lmax = 1
    lmax_1 = 1
    cg_1 = generate_clebsch_gordan(lmax_1)
    cg_sparse_1, idx_in_1_1, idx_in_2_1, idx_out_1 = sparsify_clebsch_gordon(cg_1)
    assert torch.allclose(cg_sparse_1, cg_1[cg_1 != 0], atol=1e-6)  # Use torch.allclose for numerical comparisons
    assert torch.allclose(idx_in_1_1, torch.tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]), atol=1e-6)
    assert torch.allclose(idx_in_2_1, torch.tensor([0, 1, 2, 3, 0, 2, 3, 3, 0, 1, 2, 3, 0, 1, 1, 2]), atol=1e-6)
    assert torch.allclose(idx_out_1, torch.tensor([0, 1, 2, 3, 1, 1, 0, 2, 2, 1, 0, 3, 3, 0, 2, 3]), atol=1e-6)

    # Test case 3: lmax = 2
    lmax_2 = 2
    cg_2 = generate_clebsch_gordan(lmax_2)
    cg_sparse_2, idx_in_1_2, idx_in_2_2, idx_out_2 = sparsify_clebsch_gordon(cg_2)
    print(cg_sparse_2, idx_in_1_2, idx_in_2_2, idx_out_2)
    assert torch.allclose(cg_sparse_2, cg_2[cg_2 != 0], atol=1e-6)  # Use torch.allclose for numerical comparisons
    assert torch.allclose(
        idx_in_1_2,
        torch.tensor(
            [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                4,
                4,
                4,
                4,
                4,
                4,
                4,
                4,
                4,
                4,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                5,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                6,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                7,
                8,
                8,
                8,
                8,
                8,
                8,
                8,
                8,
                8,
                8,
            ]
        ),
        atol=1e-6,
    )
    assert torch.allclose(
        idx_in_2_2,
        torch.tensor(
            [
                0,
                1,
                2,
                3,
                4,
                5,
                6,
                7,
                8,
                0,
                1,
                2,
                2,
                3,
                3,
                3,
                5,
                6,
                6,
                7,
                7,
                8,
                8,
                0,
                1,
                1,
                2,
                2,
                3,
                3,
                4,
                5,
                5,
                6,
                7,
                7,
                8,
                0,
                1,
                1,
                1,
                2,
                2,
                3,
                4,
                4,
                5,
                5,
                6,
                6,
                7,
                0,
                2,
                3,
                3,
                6,
                7,
                7,
                8,
                8,
                8,
                0,
                1,
                2,
                2,
                3,
                3,
                5,
                6,
                6,
                7,
                7,
                7,
                8,
                8,
                0,
                1,
                1,
                2,
                3,
                3,
                4,
                5,
                5,
                6,
                6,
                7,
                7,
                8,
                0,
                1,
                1,
                2,
                2,
                3,
                4,
                4,
                5,
                5,
                5,
                6,
                6,
                7,
                0,
                1,
                1,
                2,
                4,
                4,
                4,
                5,
                5,
                6,
            ]
        ),
        atol=1e-6,
    )
    assert torch.allclose(
        idx_out_2,
        torch.tensor(
            [
                0,
                1,
                2,
                3,
                4,
                5,
                6,
                7,
                8,
                1,
                4,
                1,
                5,
                0,
                2,
                6,
                4,
                1,
                5,
                2,
                6,
                3,
                7,
                2,
                1,
                5,
                0,
                6,
                3,
                7,
                4,
                1,
                5,
                2,
                3,
                7,
                8,
                3,
                0,
                2,
                6,
                3,
                7,
                8,
                1,
                5,
                2,
                6,
                3,
                7,
                8,
                4,
                4,
                1,
                5,
                4,
                1,
                5,
                0,
                2,
                6,
                5,
                4,
                1,
                5,
                2,
                6,
                4,
                1,
                5,
                0,
                2,
                6,
                3,
                7,
                6,
                1,
                5,
                2,
                3,
                7,
                4,
                1,
                5,
                0,
                6,
                3,
                7,
                8,
                7,
                2,
                6,
                3,
                7,
                8,
                1,
                5,
                0,
                2,
                6,
                3,
                7,
                8,
                8,
                3,
                7,
                8,
                0,
                2,
                6,
                3,
                7,
                8,
            ]
        ),
        atol=1e-6,
    )


def test_round_cmp():
    # Test case 1: Decimal places = 1
    x_1 = torch.tensor([1.234 + 2.345j, 3.456 + 4.567j])
    result_1 = round_cmp(x_1, decimals=1)
    expected_result_1 = torch.tensor([1.2 + 2.3j, 3.5 + 4.6j])
    assert torch.allclose(result_1, expected_result_1, atol=1e-6)  # Use torch.allclose for numerical comparisons

    # Test case 2: Decimal places = 2
    x_2 = torch.tensor([5.678 + 6.789j, 7.890 + 8.901j])
    result_2 = round_cmp(x_2, decimals=2)
    expected_result_2 = torch.tensor([5.68 + 6.79j, 7.89 + 8.90j])
    assert torch.allclose(result_2, expected_result_2, atol=1e-6)  # Use torch.allclose for numerical comparisons

    # Test case 3: Decimal places = 0
    x_3 = torch.tensor([9.876 + 1.234j, 2.345 + 3.456j])
    result_3 = round_cmp(x_3, decimals=0)
    expected_result_3 = torch.tensor([10 + 1j, 2 + 3j])
    assert torch.allclose(result_3, expected_result_3, atol=1e-6)  # Use torch.allclose for numerical comparisons
